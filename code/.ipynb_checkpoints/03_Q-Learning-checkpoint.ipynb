{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-AI-Agents\" data-toc-modified-id=\"Training-AI-Agents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training AI Agents</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Creating-the-Player-Class\" data-toc-modified-id=\"Creating-the-Player-Class-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Creating the Player Class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-in-shot_distr.csv\" data-toc-modified-id=\"Reading-in-shot_distr.csv-1.0.2.1\"><span class=\"toc-item-num\">1.0.2.1&nbsp;&nbsp;</span>Reading in shot_distr.csv</a></span></li></ul></li><li><span><a href=\"#Creating-a-custom-Environment\" data-toc-modified-id=\"Creating-a-custom-Environment-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Creating a custom Environment</a></span></li><li><span><a href=\"#Random-Agent-Decisions\" data-toc-modified-id=\"Random-Agent-Decisions-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Random Agent Decisions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.4.1\"><span class=\"toc-item-num\">1.0.4.1&nbsp;&nbsp;</span>Analysis:</a></span></li><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.4.2\"><span class=\"toc-item-num\">1.0.4.2&nbsp;&nbsp;</span>Analysis:</a></span></li></ul></li><li><span><a href=\"#Q-Learning\" data-toc-modified-id=\"Q-Learning-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Q Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis-of-Q-Learning\" data-toc-modified-id=\"Analysis-of-Q-Learning-1.0.5.1\"><span class=\"toc-item-num\">1.0.5.1&nbsp;&nbsp;</span>Analysis of Q-Learning</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training AI Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "I am using Stable Baselines, and Open AI's gym to create and test the environment. I am also brining in player.py, that will provide the probabilities of an action happening, which are determined from NBA player statistics from the current NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lots of help from Dustin Pierce at General Assembly\n",
    "#https://stable-baselines.readthedocs.io/en/master/guide/custom_env.html\n",
    "#https://github.com/koulanurag/ma-gym/blob/master/ma_gym/envs/pong_duel/pong_duel.py\n",
    "#https://github.com/hardmaru/slimevolleygym/blob/master/slimevolleygym/slimevolley.py\n",
    "#https://medium.com/@m.alzantot/you-can-see-what-is-the-observation-space-by-print-env-observation-space-c4e59e64ac52\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import random\n",
    "import time\n",
    "# import ball  --potential future add on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Player Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in shot_distr.csv\n",
    "\n",
    "I am sampling from the distributions created in the previous workbook to use as shooting percentages for the players on offense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/shot_distr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3pb</th>\n",
       "      <th>fga</th>\n",
       "      <th>fgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luka Doncic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RJ Barrett</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julius Randle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME  3pa  3pb   fga   fgb\n",
       "0  Kristaps Porzingis  6.0  8.0   8.0  13.0\n",
       "1         Luka Doncic  2.0  9.0  13.0  18.0\n",
       "2          RJ Barrett  5.0  3.0  13.0   7.0\n",
       "3       Julius Randle  2.0  5.0   9.0  11.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player():\n",
    "    \n",
    "    def __init__(self, player_name, _has_ball=False):\n",
    "\n",
    "        self.player_name = player_name\n",
    "        self._is_defended = False\n",
    "        self._has_ball = True\n",
    "        self._close_range = False\n",
    "        self._midrange = False\n",
    "        self._three_point_range = True\n",
    "\n",
    "        self.shooting_close = np.random.beta(df['fga'][df['PLAYER_NAME'] == self.player_name], df['fgb'][df['PLAYER_NAME'] == self.player_name])\n",
    "        self.shooing_midrange = np.random.beta(df['fga'][df['PLAYER_NAME'] == self.player_name], df['fgb'][df['PLAYER_NAME'] == self.player_name])\n",
    "        self.shooting3pts = np.random.beta(df['3pa'][df['PLAYER_NAME'] == self.player_name], df['3pb'][df['PLAYER_NAME'] == self.player_name])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A player on defense for this simplified game would not need attributes for shooting, because as soon as the defense gets the ball the round is over and the environment is reset. They will have attributes to determine the probability of a steal and block instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerD():\n",
    "\n",
    "    def __init__(self, player_name):\n",
    "        \n",
    "        self.player_name = player_name\n",
    "        self._is_defended = False\n",
    "        self._has_ball = False\n",
    "        self._close_range = False\n",
    "        self._midrange = False\n",
    "        self._three_point_range = True\n",
    "\n",
    "        self.steal = np.random.beta(1, 25)\n",
    "        self.block = np.random.beta(1, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment that follows gym interface.\n",
    "    This is a simple env where multiple agents learn strategies to put the ball in the hoop.\n",
    "    For this simple iteration, actions will be determined by probabilities rather than physics.\n",
    "    \"\"\"\n",
    "    # In google colab, we cannot implement the GUI ('human' render mode)\n",
    "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "\n",
    "    \n",
    "    def __init__(self, step_cost=0, reward=0, max_rounds=1):\n",
    "        #Grid size will be standard basketball halfcourt at 6\"=1'-0\" scale\n",
    "        self._grid_shape = (100, 94)\n",
    "\n",
    "        #Number of players\n",
    "        self.n_agents = 4\n",
    "        self.n_teams = 2\n",
    "        self.n_agents_team_A = int(self.n_agents / 2)\n",
    "        self.n_agents_team_B = int(self.n_agents / 2)\n",
    "        self.reward = reward\n",
    "        self._max_rounds = max_rounds\n",
    "        self.action_space = spaces.MultiDiscrete([9, 2, 2])\n",
    "        self.player_w_ball=[True, False]\n",
    "\n",
    "        self._step_count = 0\n",
    "        self._step_cost = step_cost\n",
    "        self._total_episode_reward = [0 for _ in range(self.n_teams)]\n",
    "        self.agent_pos = {_: None for _ in range(self.n_agents)}\n",
    "#         self.x = [self.agent_pos[x][0] for x in range(0,4)]\n",
    "#         self.y = [self.agent_pos[y][1] for y in range(0,4)]\n",
    "#         self.t = 24\n",
    "\n",
    "        self._agent_dones = None\n",
    "        self._rounds = 0\n",
    "\n",
    "        # Observing agent positions for 4 agents\n",
    "        self._obs_low = np.array([0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        self._obs_high = np.array([1., 1., 1., 1., 1., 1., 1., 1,])\n",
    "        self.observation_space = spaces.Box(low=self._obs_low, high=self._obs_high,\n",
    "                                        dtype=np.float32)\n",
    "\n",
    "        self.viewer = None\n",
    "        self.seed()\n",
    "        \n",
    "    def is_done(self):\n",
    "        if self._rounds >= self._max_rounds:\n",
    "            return True\n",
    "        \n",
    "    def get_action_meanings(self, agent_i=None):\n",
    "        if agent_i is not None:\n",
    "            assert agent_i <= self.n_agents\n",
    "            return [ACTION_MEANING[i] for i in range(self.action_space[agent_i].n)]\n",
    "        else:\n",
    "            return [[ACTION_MEANING[i] for i in range(ac.n)] for ac in self.action_space]\n",
    "\n",
    "    def __create_grid(self):\n",
    "        _grid = [[PRE_IDS['empty'] for _ in range(self._grid_shape[1])] for row in range(self._grid_shape[0])]\n",
    "        return _grid\n",
    "\n",
    "    def __update_agent_view(self, agent_i):\n",
    "        for row in range(self.agent_prev_pos[agent_i][0],\n",
    "                         self.agent_prev_pos[agent_i][0]):\n",
    "            self._full_obs[row][self.agent_prev_pos[agent_i][1]] = PRE_IDS['empty']\n",
    "\n",
    "        for row in range(self.agent_pos[agent_i][0], self.agent_pos[agent_i][0]):\n",
    "            self._full_obs[row][self.agent_pos[agent_i][1]] = PRE_IDS['agent'] + str(agent_i + 1) \\\n",
    "                                                              + '_' + str(row - self.agent_pos[agent_i][0])\n",
    "\n",
    "#     def __draw_base_img(self):\n",
    "#         self._base_img = draw.draw_grid(self._grid_shape[0], self._grid_shape[1],\n",
    "#                                    cell_size=CELL_SIZE, fill='white', line_color='white')\n",
    "\n",
    "    def __init_full_obs(self):\n",
    "        self._full_obs = self.__create_grid()\n",
    "        for agent_i in range(self.n_agents):\n",
    "            self.__update_agent_view(agent_i)\n",
    "\n",
    "        for agent_i in range(self.n_agents):\n",
    "            self.__update_agent_view(agent_i)\n",
    "\n",
    "#         self.__draw_base_img()\n",
    "\n",
    "    #Countdown timer as 24 second shot clock for each round\n",
    "    #https://www.geeksforgeeks.org/how-to-create-a-countdown-timer-using-python/\n",
    "#     def countdown(self, t=24):     \n",
    "#         while t: \n",
    "#             mins, secs = divmod(t, 60) \n",
    "#             timer = '{:02d}:{:02d}'.format(mins, secs)  \n",
    "#             time.sleep(1) \n",
    "#             t -= 1\n",
    "#             self.t = t\n",
    "    \n",
    "#     def __init_countdown(self, t):\n",
    "#         return self.countdown(t)\n",
    "        \n",
    "\n",
    "    def get_agent_obs(self):\n",
    "        _obs = []\n",
    "\n",
    "        for agent_i in range(self.n_agents):\n",
    "            pos = self.agent_pos[agent_i]\n",
    "            _agent_i_obs_a = pos[0] / self._grid_shape[0]\n",
    "            _agent_i_obs_b = pos[1] / self._grid_shape[1]\n",
    "            \n",
    "            _obs.append(_agent_i_obs_a)\n",
    "            _obs.append(_agent_i_obs_b)\n",
    "\n",
    "        return np.array(_obs)\n",
    "    \n",
    "    def get_state_num(self):\n",
    "        for agent_i in range(self.n_agents):\n",
    "            return self.agent_pos[agent_i][0]*self._grid_shape[0] + self.agent_pos[agent_i][1]\n",
    "\n",
    "    def get_pos_from_state_num(self, state_num):\n",
    "        return (state_num // self._grid_shape[0], state_num % self._grid_shape[0])\n",
    "    \n",
    "##############\n",
    "#Define Reset#   \n",
    "##############\n",
    "\n",
    "    def reset(self):\n",
    "        self._rounds = 0\n",
    "#         self.__init_countdown(24)\n",
    "        \n",
    "        #Set starting positions for agents in Team A\n",
    "        self.agent_pos[0] = [self._grid_shape[0]//2, self._grid_shape[1] - 2]\n",
    "        self.agent_pos[1] = [self._grid_shape[0]//5, self._grid_shape[1] - 2]\n",
    "\n",
    "        \n",
    "        #Set starting positions for agents in Team B\n",
    "        self.agent_pos[2] = [self._grid_shape[0]//2, self._grid_shape[1] - 8]\n",
    "        self.agent_pos[3] = [self._grid_shape[0]//5, self._grid_shape[1] - 8]\n",
    "\n",
    "        \n",
    "        self.agent_prev_pos = {_: self.agent_pos[_] for _ in range(self.n_agents)}\n",
    "        self._agent_dones = False\n",
    "        self.__init_full_obs()\n",
    "        self._step_count = 0\n",
    "        self._total_episode_reward = [0 for _ in range(self.n_teams)]\n",
    "\n",
    "        return self.get_agent_obs()\n",
    "\n",
    "    \n",
    "###############################\n",
    "#Define Properties and Actions#   \n",
    "###############################\n",
    "    \n",
    "            \n",
    "    #This will determine success of an action\n",
    "    def action_success(self, p_1):\n",
    "        return np.random.choice([0, 1], p=[1 - p_1, p_1])\n",
    "\n",
    "    #Determine if a player is close to the goal\n",
    "    def close_range(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if np.sqrt((self.pos[agent_i][0] - GOAL[0])**2 + (self.pos[agent_i][1]-GOAL[1])**2) <= 6:\n",
    "                player._close_range = True\n",
    "                player._midrange = False\n",
    "                player._three_point_range = False\n",
    "\n",
    "    #Determine if a player is mid-range from the goal\n",
    "    def midrange(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if player._close_range == False and player._three_point_range == False:\n",
    "                player._midrange = True\n",
    "                    \n",
    "\n",
    "    #Determine if a player is in three point range\n",
    "    def _three_point_range(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if self.pos[agent_i][1] <= 19.67 and self.pos[agent_i][0] <= 6.67 or self.pos[agent_i][1] >= 93.33:\n",
    "                player._three_point_range = True\n",
    "            elif self.pos[agent_i][1] > 19.67 and np.sqrt((self.pos[agent_i][0] - GOAL[0])**2 + (self.pos[agent_i][1]-GOAL[1])**2) > 44.3:\n",
    "                player._three_point_range = True\n",
    "                player._midrange = False\n",
    "                player._close_range = False\n",
    "        \n",
    "    def rebound(self):\n",
    "        if self.action_success(0.3):\n",
    "            #UPDATE THE PLAYER_W_BALL:\n",
    "#                 o_rebounder = random.choice([[True, False], [False, True]])\n",
    "#                 self.player_w_ball = o_rebounder\n",
    "#                 self.__init_countdown(14)\n",
    "#                 if o_rebounder == [True, False]:\n",
    "#                     player._has_ball = True\n",
    "#                     player2._has_ball = False\n",
    "#                 else:\n",
    "#                     player._has_ball = False\n",
    "#                     player2._has_ball = True\n",
    "            return 0.2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    #define shot, a made shot will be a reward for the offensive team\n",
    "    def shot(self):\n",
    "\n",
    "        #Can only shoot if the player has the ball -- [1,0]\n",
    "        if self.player_w_ball==[1,0]:\n",
    "\n",
    "            #Close range shot\n",
    "            if player._close_range:\n",
    "                if self.action_success(player.shooting_close):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "            #3 point shot\n",
    "            if player._three_point_range:\n",
    "                if self.action_success(player.shooting3pts):\n",
    "                    return 3\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "            #Midrange shot\n",
    "            else:\n",
    "                if self.action_success(player.shooting_midrange):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "        #Can only shoot if the player has the ball -- [0,1]\n",
    "        if self.player_w_ball==[0,1]:\n",
    "\n",
    "            #Close range shot\n",
    "            if player2._close_range:\n",
    "                if self.action_success(player2.shooting_close):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "            #3 point shot\n",
    "            if player2._three_point_range:\n",
    "                if self.action_success(player2.shooting3pts):\n",
    "                    return 3\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "            #Midrange shot\n",
    "            else:\n",
    "                if self.action_success(player2.shooting_midrange):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "                        \n",
    "    def ball_pass(self):\n",
    "        if self.player_w_ball == [1,0]:\n",
    "            player._has_ball = False\n",
    "            player2._has_ball = True\n",
    "            self.player_w_ball = [0,1]\n",
    "\n",
    "        if self.player_w_ball == [0,1]:\n",
    "            player._has_ball = True\n",
    "            player2._has_ball = False\n",
    "            self.player_w_ball = [1,0]\n",
    "                \n",
    "            \n",
    "\n",
    "    def defended(self):\n",
    "        for agent_j in [2,3]:\n",
    "            if np.sqrt(self.pos[0][0]-self.pos[agent_j][0]**2 + self.pos[0][1]-self.pos[agent_j][1]**2) < 5:\n",
    "                player._is_defended=True\n",
    "            if np.sqrt(self.pos[1][0]-self.pos[agent_j][0]**2 + self.pos[1][1]-self.pos[agent_j][1]**2) < 5:\n",
    "                player2._is_defended=True\n",
    "            else:\n",
    "                player._is_defended=False\n",
    "                player2._is_defended=False\n",
    "    \n",
    "    def steal(self):\n",
    "        if player._has_ball and player._is_defended:\n",
    "            return action_success(0.02)\n",
    "        if player2._has_ball and player2._is_defended:\n",
    "            return action_success(0.02)\n",
    "        \n",
    "    \n",
    "    def block(self):\n",
    "        if player._has_ball and player._is_defended and player._close_range:\n",
    "            return action_success(0.04)\n",
    "        if player._has_ball and player._is_defended and player._midrange:\n",
    "            return action_success(0.03)\n",
    "        if player._has_ball and player._is_defended and player._three_point_range:\n",
    "            return action_success(0.02)\n",
    "        if player2._has_ball and player2._is_defended and player2._close_range:\n",
    "            return action_success(0.04)\n",
    "        if player2._has_ball and player2._is_defended and player2._midrange:\n",
    "            return action_success(0.03)\n",
    "        if player2._has_ball and player2._is_defended and player2._three_point_range:\n",
    "            return action_success(0.02)\n",
    "                \n",
    "    def out_of_bounds(self):\n",
    "        for agent_x in range(self.n_agents):\n",
    "            if self.agent_pos[agent_x][0] > 0 and self.agent_pos[agent_x][0] < self._grid_shape[0] and self.agent_pos[agent_x][1] > 0 and self.agent_pos[agent_x][1] < self._grid_shape[1]:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "    def is_valid(self, pos):\n",
    "        return (0 <= pos[0] < self._grid_shape[0]) and (0 <= pos[1] < self._grid_shape[1])\n",
    "\n",
    "    def _is_cell_vacant(self, pos):\n",
    "        return self.is_valid(pos) and (self._full_obs[pos[0]][pos[1]] == PRE_IDS['empty'])\n",
    "\n",
    "    \n",
    "    \n",
    "###############\n",
    "#Define Render#   \n",
    "###############\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        img = copy.copy(self._base_img)\n",
    "        for agent_i in range(self.n_agents):\n",
    "            for row in self.agent_pos[agent_i][0]:\n",
    "                fill_cell(img, (row, self.agent_pos[agent_i][1]), cell_size=CELL_SIZE, fill=AGENT_COLORS[agent_i])\n",
    "\n",
    "        img = draw_border(img, border_width=2, fill='gray')\n",
    "\n",
    "        img = np.asarray(img)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "    def __update_agent_pos(self, agent_i, move):\n",
    "\n",
    "        curr_pos = copy.copy(self.agent_pos[agent_i])\n",
    "        for agent_i in range(self.n_agents):\n",
    "\n",
    "            if move == 0:  # noop\n",
    "                next_pos = None\n",
    "            elif move == 1:  # up\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1]]\n",
    "            elif move == 2:  # upright\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1] + 1]\n",
    "            elif move == 3:  # right\n",
    "                next_pos = [curr_pos[0], curr_pos[1] + 1]\n",
    "            elif move == 4:  # downright\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1] + 1]\n",
    "            elif move == 5:  # down\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1]]\n",
    "            elif move == 6:  # downleft\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1] - 1]\n",
    "            elif move == 7:  # left\n",
    "                next_pos = [curr_pos[0], curr_pos[1] - 1]\n",
    "            elif move == 8:  # upleft\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1] - 1]\n",
    "#                 else:\n",
    "#                     raise Exception('Action Not found!')\n",
    "\n",
    "\n",
    "            if move in range(1,9):\n",
    "                self.agent_prev_pos[agent_i] = self.agent_pos[agent_i]\n",
    "                self.agent_pos[agent_i] = next_pos\n",
    "                self.__update_agent_view(agent_i)\n",
    "            \n",
    "\n",
    "#############\n",
    "#Define Seed#   \n",
    "#############\n",
    "\n",
    "    def seed(self, n=None):\n",
    "        self.np_random, seed = seeding.np_random(n)\n",
    "        return [seed]\n",
    "\n",
    "#############\n",
    "#Define Step#   \n",
    "#############\n",
    "    \n",
    "    def step(self, action_n=[0,0,0,0]):\n",
    "        assert len(action_n) == self.n_agents\n",
    "        self._step_count += 1\n",
    "        rewards = [self._step_cost for _ in range(self.n_teams)]\n",
    "        \n",
    "        for agent, action in enumerate(action_n):\n",
    "            \n",
    "            if action == \"UP\" and self.agent_pos[agent][1] > 0:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "            elif action == \"UPLEFT\" and self.agent_pos[agent][1] > 0 and self.agent_pos[agent][0] > 0:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "            elif action == \"LEFT\" and self.agent_pos[agent][0] > 0:\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "            elif action == \"DOWNLEFT\" and self.agent_pos[agent][0] > 0 and self.agent_pos[agent][1] < self._grid_shape[1]-1:\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"DOWN\" and self.agent_pos[agent][1] < self._grid_shape[1]-1:\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"DOWNRIGHT\" and self.agent_pos[agent][1] < self._grid_shape[1]-1  and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"RIGHT\" and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][0] += 1\n",
    "            elif action == \"UPRIGHT\" and self.agent_pos[agent][1] > 0 and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "                self.agent_pos[agent][0] += 1\n",
    "                \n",
    "            if agent == 0 or agent == 1:\n",
    "                if action_n == 'SHOOT':\n",
    "                    self.shot()\n",
    "                    # if shot made, new round\n",
    "                    if fga == 2:\n",
    "                        rewards = [2, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 3:\n",
    "                        rewards = [3, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 1:\n",
    "                        rewards = [0, 1]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 0.2:\n",
    "                        rewards = [0.2, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                elif action_n == 'BALL_PASS':\n",
    "                    self.ball_pass()\n",
    "            if agent == 2 or agent == 3:\n",
    "                if action_n == 'BALL_PASS':\n",
    "                    st = self.steal()\n",
    "                    # if steal made, new round\n",
    "                    if st == 1:\n",
    "                        rewards = [0, 2]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                elif action_n == 'SHOOT':\n",
    "                    bl = self.block()\n",
    "                    # if block made, new round\n",
    "                    if bl == 1:\n",
    "                        rewards = [0, 2]\n",
    "                        self._rounds += 1\n",
    "            \n",
    "        # if Offense fails to get off a shot within time limit, new round\n",
    "#         if self.t < 1:\n",
    "#             rewards = [0, 2]\n",
    "#             self._agent_dones = True\n",
    "#             self._rounds += 1\n",
    "            \n",
    "        if self.out_of_bounds():\n",
    "            rewards = [-10, -10]\n",
    "            self._rounds +=1\n",
    "            \n",
    "        if self.rebound() == 0.2:\n",
    "            rewards = [0.2, 0]\n",
    "            self._rounds +=1\n",
    "            \n",
    "        if self.rebound() == 1:\n",
    "            rewards = [0, 1]\n",
    "            self._rounds += 1\n",
    "                        \n",
    "        if self._rounds == self._max_rounds:\n",
    "            self._agent_dones = True\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            for agent_i in range(self.n_agents_team_A):\n",
    "                self.__update_agent_pos(agent_i, action_n[agent_i])\n",
    "            for agent_j in range(self.n_agents_team_B):\n",
    "                self.__update_agent_pos(agent_j, action_n[agent_j])\n",
    "                \n",
    "        for i in range(self.n_teams):\n",
    "            self._total_episode_reward[i] += rewards[i]\n",
    "\n",
    "        return self.get_agent_obs(), rewards[0]-rewards[1], self._agent_dones, {'rounds': self._rounds}\n",
    "    \n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "# Define constants for clearer code\n",
    "\n",
    "CELL_SIZE = 5\n",
    "\n",
    "#Goal Location\n",
    "GOAL = [50, 10.5]\n",
    "\n",
    "ACTION_MEANING = {\n",
    "    0 : 'NOOP',\n",
    "    1 : 'UP',\n",
    "    2 : 'UPRIGHT',\n",
    "    3 : 'RIGHT',\n",
    "    4 : 'DOWNRIGHT',\n",
    "    5 : 'DOWN',\n",
    "    6 : 'DOWNLEFT',\n",
    "    7 : 'LEFT',\n",
    "    8 : 'UPLEFT',\n",
    "    9 : 'BALL_PASS',\n",
    "    10 : 'SHOOT',\n",
    "}\n",
    "\n",
    "AGENT_TEAMS = {\n",
    "    0: 'A',\n",
    "    1: 'A',\n",
    "    2: 'B',\n",
    "    3: 'B',\n",
    "}\n",
    "\n",
    "AGENT_COLORS = {\n",
    "    0: 'red',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'blue',\n",
    "}\n",
    "\n",
    "WALL_COLOR = 'black'\n",
    "\n",
    "# each pre-id should be unique and single char\n",
    "PRE_IDS = {\n",
    "    'agent': 'A',\n",
    "    'goal' : 'G',\n",
    "    'empty': 'O'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgentA:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0\n",
    "        player = Player('Luka Doncic', _has_ball=True)\n",
    "        player2 = Player('Kristaps Porzingis', _has_ball=False)\n",
    "        player3 = Player('RJ Barrett', _has_ball=False)\n",
    "        player4 = Player('Julius Randle', _has_ball=False)\n",
    "\n",
    "    def step(self, env):\n",
    "        # current_obs = env.get_observation()\n",
    "        actions = ACTION_MEANING\n",
    "        action = [random.choice(actions), random.choice(actions), random.choice(actions), random.choice(actions)]\n",
    "        reward = env.step(action)\n",
    "        print(f\"Took action {action} and got reward {self.total_reward}\")\n",
    "        self.total_reward += reward[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the Random agent and Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RandomAgentA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendr\\anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = BasketballEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way it is set up, the environment needs to be reset after instantiation and before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took action ['SHOOT', 'DOWNLEFT', 'RIGHT', 'RIGHT'] and got reward 0\n",
      "Total reward: -1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "count = 0\n",
    "while not env.is_done():\n",
    "    agent.step(env)\n",
    "    count+=1\n",
    "print(f\"Total reward: {agent.total_reward}\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "The agent took a shot and the defense got the rebound. I will step through random actions in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5       , 0.9787234 , 0.18      , 0.9893617 , 0.5       ,\n",
       "        0.92553191, 0.22      , 0.90425532]),\n",
       " -1,\n",
       " False,\n",
       " {'rounds': 4})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([random.choice(ACTION_MEANING),random.choice(ACTION_MEANING),random.choice(ACTION_MEANING),random.choice(ACTION_MEANING)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "The environment is working. The agents are not in their initial positions and the reward was given to the defense for a defensive rebound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount for future rewards\n",
    "gamma = 0.9\n",
    "\n",
    "# the learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "# exploration-exploitation tradeoff: proportion of time to take a random action\n",
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player = Player('RJ Barrett', _has_ball=True)\n",
    "player2 = Player('Julius Randle', _has_ball=False)\n",
    "env = BasketballEnv()\n",
    "env.reset()\n",
    "episodes = 250000\n",
    "\n",
    "# Q(s,a): \"quality\" of taking action a in state s\n",
    "num_states = env._grid_shape[0]*env._grid_shape[1]\n",
    "num_actions = len(ACTION_MEANING)\n",
    "q_table = np.zeros([num_states, num_actions])\n",
    "\n",
    "for _ in range(0,episodes):\n",
    "    player = Player('Luka Doncic', _has_ball=True)\n",
    "    player2 = Player('Kristaps Porzingis', _has_ball=False)\n",
    "\n",
    "    env.reset()\n",
    "    state = env.get_state_num()\n",
    "\n",
    "    while not env.is_done():\n",
    "        # epsilon-greedy policy\n",
    "        actions = ACTION_MEANING\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = [random.choice(actions), random.choice(actions), random.choice(actions), random.choice(actions)]\n",
    "        else:\n",
    "            action_index = np.random.choice(np.flatnonzero(q_table[state] == q_table[state].max()))\n",
    "            action = [actions[action_index], actions[action_index], actions[action_index], actions[action_index]]\n",
    "\n",
    "        reward = env.step(action)[1]\n",
    "        state2 = env.get_state_num()\n",
    "\n",
    "        # Q-update\n",
    "        old_q = q_table[state,action_index]\n",
    "        max_q2 = np.max(q_table[state2])\n",
    "        q_table[state,action_index] = old_q + alpha*(reward + gamma*max_q2 - old_q)\n",
    "\n",
    "        #print(f\"s={state}, a={action}, s'={state2}, r={reward}, old_q={old_q}, new_q={q_table[state,action_index]}\")\n",
    "\n",
    "        state = state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if there are non-zero values in the q-table that aren't being seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q = pd.DataFrame(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_q.value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Q-table Heatmap')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,12))\n",
    "sns.heatmap(q_table[4600:5400], vmin=0, vmax=-1)\n",
    "plt.title('Q-table Heatmap', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.1       , -0.199     , -0.62725732, -0.85534299,\n",
       "       -0.84673988, -0.4900995 , -0.71933374, -1.46841166, -1.52002688,\n",
       "       -1.61533535, -1.60106868, -0.83832106, -1.63817211, -2.1932608 ,\n",
       "       -2.239829  , -2.27779   , -0.19801   , -0.86482753, -1.57268417,\n",
       "       -2.23966335, -2.83211296, -2.27900243, -0.72504025, -1.49794466,\n",
       "       -2.26431518, -2.26431678, -1.69223802, -1.22451469, -1.70682666,\n",
       "       -1.34342921, -0.73984271, -0.5631048 , -0.75916925, -0.43666335])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q[9].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.patches import Circle, Rectangle, Arc\n",
    "import matplotlib as mpl\n",
    "#https://www.jphwang.com/nba-shot-data-analytics-visualization-with-python-pandas-and-matplotlib-part-2-grouping-data-by-area/\n",
    "# Amazing function by Bradley Fay for plotting the nba court\n",
    "# source: https://github.com/bradleyfay/py-Goldsberry/blob/master/docs/Visualizing%20NBA%20Shots%20with%20py-Goldsberry.ipynb\n",
    "def create_court(ax, color):\n",
    "    \n",
    "    # Short corner 3PT lines\n",
    "    ax.plot([-220, -220], [0, 140], linewidth=2, color=color)\n",
    "    ax.plot([220, 220], [0, 140], linewidth=2, color=color)\n",
    "    \n",
    "    # 3PT Arc\n",
    "    ax.add_artist(mpl.patches.Arc((0, 140), 440, 315, theta1=0, theta2=180, facecolor='none', edgecolor=color, lw=2))\n",
    "    \n",
    "    # Lane and Key\n",
    "    ax.plot([-80, -80], [0, 190], linewidth=2, color=color)\n",
    "    ax.plot([80, 80], [0, 190], linewidth=2, color=color)\n",
    "    ax.plot([-60, -60], [0, 190], linewidth=2, color=color)\n",
    "    ax.plot([60, 60], [0, 190], linewidth=2, color=color)\n",
    "    ax.plot([-80, 80], [190, 190], linewidth=2, color=color)\n",
    "    ax.add_artist(mpl.patches.Circle((0, 190), 60, facecolor='none', edgecolor=color, lw=2))\n",
    "    \n",
    "    # Rim\n",
    "    ax.add_artist(mpl.patches.Circle((0, 60), 15, facecolor='none', edgecolor=color, lw=2))\n",
    "    \n",
    "    # Backboard\n",
    "    ax.plot([-30, 30], [40, 40], linewidth=2, color=color)\n",
    "    \n",
    "    # Remove ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Set axis limits\n",
    "    ax.set_xlim(-250, 250)\n",
    "    ax.set_ylim(0, 470)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4*3, 3.76*3))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "# Draw court\n",
    "ax = create_court(ax, 'grey')\n",
    "\n",
    "# Plot hexbin of shots\n",
    "ax.hexbin(df_q[9] // env._grid_shape[0], df_q[9] % env._grid_shape[1], gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='mako', alpha=.95)\n",
    "\n",
    "# Annotate player name and season\n",
    "plt.title('Coach AI Q-Table Shot Chart', transform=ax.transAxes, ha='center', fontsize=18, pad=15)\n",
    "\n",
    "# Save and show figure\n",
    "# plt.savefig('../images/bgriffin_1516.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_per_grid = 5\n",
    "im = Image.open('../images/Basketball_court-Model.jpg')\n",
    "draw = ImageDraw.Draw(im)\n",
    "# im = im.rotate(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent_i in [0,1]:\n",
    "    drawCirc(draw, env.agent_pos[agent_i][0]*5, env.agent_pos[agent_i][1]*5, 'blue')\n",
    "for agent_i in [2,3]:\n",
    "    drawRect(draw, env.agent_pos[agent_i][0]*5, env.agent_pos[agent_i][1]*5, 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env._grid_shape[1]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.new(\"RGB\", (500, 470), 'white')\n",
    "drawText = ImageDraw.Draw(image)\n",
    "fnt = ImageFont.truetype(\"C:/Windows/Fonts/arial.ttf \", 36)\n",
    "def drawText(img, txt, x, y, color):\n",
    "    img.text([x*image.size[0], y*image.size[1]], txt, fnt=fnt, fill=color)\n",
    "\n",
    "if q_table is not None:\n",
    "        arrows = ['N/A', '^','^>','>','v>','v','<v','<','^<', 'O', 'P']\n",
    "        num_states = env._grid_shape[0] * env._grid_shape[1]\n",
    "        for s in range(num_states):\n",
    "            (x,y) = env.get_pos_from_state_num(s)\n",
    "            action_index = np.argmax(q_table[s])\n",
    "            arrow = arrows[action_index]\n",
    "            drawText(draw, arrow, x, y, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization parameters\n",
    "gridsize = 5    # pixels per grid square\n",
    "border = 1         # in pixels\n",
    "\n",
    "def drawRect(img, x, y, color):\n",
    "    img.rectangle([x*gridsize+4*border, y*gridsize+4*border, (x+1)*gridsize-2*border, (y+1)*gridsize-2*border], fill=color)\n",
    "\n",
    "def drawCirc(img, x, y, color):\n",
    "    img.rectangle([x*gridsize+4*border, y*gridsize+4*border, (x+1)*gridsize-2*border, (y+1)*gridsize-2*border], fill=color)    \n",
    "    \n",
    "def drawText(img, txt, x, y, color):\n",
    "    img.text([x*gridsize+4*border, y*gridsize+4*border], txt, fnt=fnt, fill=color)\n",
    "\n",
    "def drawEnvironment(env, q_table=None):\n",
    "    imageSize = env._grid_shape[0]*env._grid_shape[1]*gridsize + border*2\n",
    "    image = Image.new(\"RGB\", (imageSize, imageSize), 'white')\n",
    "    imageDraw = ImageDraw.Draw(image)\n",
    "    # draw the grid\n",
    "    for row in range(env._grid_shape[0]+1):\n",
    "        imageDraw.line([border, row*gridsize+border, imageSize-border, row*gridsize+border], 'black', border)\n",
    "    for col in range(env._grid_shape[1]+1):\n",
    "        imageDraw.line([col*gridsize+border, border, col*gridsize+border, imageSize-border], 'black', border)\n",
    "\n",
    "    # agent is blue, goal is red, and walls are black\n",
    "    for agent_i in [0,1]:\n",
    "        drawCirc(imageDraw, env.agent_pos[agent_i][0], env.agent_pos[agent_i][1], 'blue')\n",
    "    for agent_i in [2,3]:\n",
    "        drawRect(imageDraw, env.agent_pos[agent_i][0], env.agent_pos[agent_i][1], 'blue')\n",
    "\n",
    "    drawItem(imageDraw, env.GOAL[0], env.GOAL[1], 'orange')\n",
    "\n",
    "    if q_table is not None:\n",
    "        arrows = ['^','^>','>','v>','v','<v','<','^<', 'O', 'P']\n",
    "        num_states = env.num_states()\n",
    "        for s in range(num_states):\n",
    "            (x,y) = env.get_pos_from_state_num(s)\n",
    "            action_index = np.argmax(q_table[s])\n",
    "            arrow = arrows[action_index]\n",
    "            drawText(imageDraw, arrow, x, y, 'green')\n",
    "\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agents definitely learned that some actions led to worse rewards from the heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
