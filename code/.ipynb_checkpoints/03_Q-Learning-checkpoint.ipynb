{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-AI-Agents\" data-toc-modified-id=\"Training-AI-Agents-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training AI Agents</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Imports</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stable-Baselines-Imports\" data-toc-modified-id=\"Stable-Baselines-Imports-1.0.1.1\"><span class=\"toc-item-num\">1.0.1.1&nbsp;&nbsp;</span>Stable Baselines Imports</a></span></li></ul></li><li><span><a href=\"#Creating-the-Player-Class\" data-toc-modified-id=\"Creating-the-Player-Class-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Creating the Player Class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-in-shot_distr.csv\" data-toc-modified-id=\"Reading-in-shot_distr.csv-1.0.2.1\"><span class=\"toc-item-num\">1.0.2.1&nbsp;&nbsp;</span>Reading in shot_distr.csv</a></span></li></ul></li><li><span><a href=\"#Creating-a-custom-Environment\" data-toc-modified-id=\"Creating-a-custom-Environment-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Creating a custom Environment</a></span></li><li><span><a href=\"#Checking-the-environment-using-Stable-Baselines\" data-toc-modified-id=\"Checking-the-environment-using-Stable-Baselines-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Checking the environment using Stable Baselines</a></span></li><li><span><a href=\"#Random-Agent-Decisions\" data-toc-modified-id=\"Random-Agent-Decisions-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Random Agent Decisions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.5.1\"><span class=\"toc-item-num\">1.0.5.1&nbsp;&nbsp;</span>Analysis:</a></span></li><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.5.2\"><span class=\"toc-item-num\">1.0.5.2&nbsp;&nbsp;</span>Analysis:</a></span></li></ul></li><li><span><a href=\"#Q-Learning\" data-toc-modified-id=\"Q-Learning-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Q Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis-of-Q-Learning\" data-toc-modified-id=\"Analysis-of-Q-Learning-1.0.6.1\"><span class=\"toc-item-num\">1.0.6.1&nbsp;&nbsp;</span>Analysis of Q-Learning</a></span></li></ul></li><li><span><a href=\"#PPO---Promixal-Policy-Optimization\" data-toc-modified-id=\"PPO---Promixal-Policy-Optimization-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>PPO - Promixal Policy Optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.7.1\"><span class=\"toc-item-num\">1.0.7.1&nbsp;&nbsp;</span>Analysis:</a></span></li></ul></li><li><span><a href=\"#PPO2---Promixal-Policy-Optimization\" data-toc-modified-id=\"PPO2---Promixal-Policy-Optimization-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>PPO2 - Promixal Policy Optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.8.1\"><span class=\"toc-item-num\">1.0.8.1&nbsp;&nbsp;</span>Analysis:</a></span></li></ul></li><li><span><a href=\"#A2C---Advantage-Actor-Critic\" data-toc-modified-id=\"A2C---Advantage-Actor-Critic-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>A2C - Advantage Actor Critic</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysis:\" data-toc-modified-id=\"Analysis:-1.0.9.1\"><span class=\"toc-item-num\">1.0.9.1&nbsp;&nbsp;</span>Analysis:</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training AI Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "I am using Stable Baselines, and Open AI's gym to create and test the environment. I am also brining in player.py, that will provide the probabilities of an action happening, which are determined from NBA player statistics from the current NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lots of help from Dustin Pierce at General Assembly\n",
    "#https://stable-baselines.readthedocs.io/en/master/guide/custom_env.html\n",
    "#https://github.com/koulanurag/ma-gym/blob/master/ma_gym/envs/pong_duel/pong_duel.py\n",
    "#https://github.com/hardmaru/slimevolleygym/blob/master/slimevolleygym/slimevolley.py\n",
    "#https://medium.com/@m.alzantot/you-can-see-what-is-the-observation-space-by-print-env-observation-space-c4e59e64ac52\n",
    "\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import random\n",
    "import time\n",
    "# import ball  --potential future add on\n",
    "# from player import Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Player Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in shot_distr.csv\n",
    "\n",
    "I am sampling from the distributions created in the previous workbook to use as shooting percentages for the players on offense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/shot_distr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3pb</th>\n",
       "      <th>fga</th>\n",
       "      <th>fgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luka Doncic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RJ Barrett</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julius Randle</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME  3pa  3pb   fga   fgb\n",
       "0  Kristaps Porzingis  6.0  8.0   8.0  13.0\n",
       "1         Luka Doncic  2.0  9.0  13.0  18.0\n",
       "2          RJ Barrett  5.0  3.0  13.0   7.0\n",
       "3       Julius Randle  2.0  5.0   9.0  11.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player():\n",
    "    \n",
    "    def __init__(self, player_name, _has_ball=False):\n",
    "\n",
    "        self.player_name = player_name\n",
    "        self._is_defended = False\n",
    "        self._has_ball = True\n",
    "        self._close_range = False\n",
    "        self._midrange = False\n",
    "        self._three_point_range = True\n",
    "\n",
    "        self.shooting_close = np.random.beta(df['fga'][df['PLAYER_NAME'] == self.player_name], df['fgb'][df['PLAYER_NAME'] == self.player_name])\n",
    "        self.shooing_midrange = np.random.beta(df['fga'][df['PLAYER_NAME'] == self.player_name], df['fgb'][df['PLAYER_NAME'] == self.player_name])\n",
    "        self.shooting3pts = np.random.beta(df['3pa'][df['PLAYER_NAME'] == self.player_name], df['3pb'][df['PLAYER_NAME'] == self.player_name])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A player on defense for this simplified game would not need attributes for shooting, because as soon as the defense gets the ball the round is over and the environment is reset. They will have attributes to determine the probability of a steal and block instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerD():\n",
    "\n",
    "    def __init__(self, player_name):\n",
    "        \n",
    "        self.player_name = player_name\n",
    "        self._is_defended = False\n",
    "        self._has_ball = False\n",
    "        self._close_range = False\n",
    "        self._midrange = False\n",
    "        self._three_point_range = True\n",
    "\n",
    "        self.steal = np.random.beta(1, 25)\n",
    "        self.block = np.random.beta(1, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment that follows gym interface.\n",
    "    This is a simple env where multiple agents learn strategies to put the ball in the hoop.\n",
    "    For this simple iteration, actions will be determined by probabilities rather than physics.\n",
    "    \"\"\"\n",
    "    # In google colab, we cannot implement the GUI ('human' render mode)\n",
    "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "\n",
    "    \n",
    "    def __init__(self, step_cost=0, reward=0, max_rounds=1):\n",
    "        #Grid size will be standard basketball halfcourt at 6\"=1'-0\" scale\n",
    "        self._grid_shape = (100, 94)\n",
    "\n",
    "        #Number of players\n",
    "        self.n_agents = 4\n",
    "        self.n_teams = 2\n",
    "        self.n_agents_team_A = int(self.n_agents / 2)\n",
    "        self.n_agents_team_B = int(self.n_agents / 2)\n",
    "        self.reward = reward\n",
    "        self._max_rounds = max_rounds\n",
    "        self.action_space = spaces.MultiDiscrete([9, 2, 2])\n",
    "        self.player_w_ball=[True, False]\n",
    "\n",
    "        self._step_count = 0\n",
    "        self._step_cost = step_cost\n",
    "        self._total_episode_reward = [0 for _ in range(self.n_teams)]\n",
    "        self.agent_pos = {_: None for _ in range(self.n_agents)}\n",
    "#         self.x = [self.agent_pos[x][0] for x in range(0,4)]\n",
    "#         self.y = [self.agent_pos[y][1] for y in range(0,4)]\n",
    "#         self.t = 24\n",
    "\n",
    "        self._agent_dones = None\n",
    "        self._rounds = 0\n",
    "\n",
    "        # Observing agent positions for 4 agents\n",
    "        self._obs_low = np.array([0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        self._obs_high = np.array([1., 1., 1., 1., 1., 1., 1., 1,])\n",
    "        self.observation_space = spaces.Box(low=self._obs_low, high=self._obs_high,\n",
    "                                        dtype=np.float32)\n",
    "\n",
    "        self.viewer = None\n",
    "        self.seed()\n",
    "        \n",
    "    def is_done(self):\n",
    "        if self._rounds >= self._max_rounds:\n",
    "            return True\n",
    "        \n",
    "    def get_action_meanings(self, agent_i=None):\n",
    "        if agent_i is not None:\n",
    "            assert agent_i <= self.n_agents\n",
    "            return [ACTION_MEANING[i] for i in range(self.action_space[agent_i].n)]\n",
    "        else:\n",
    "            return [[ACTION_MEANING[i] for i in range(ac.n)] for ac in self.action_space]\n",
    "\n",
    "    def __create_grid(self):\n",
    "        _grid = [[PRE_IDS['empty'] for _ in range(self._grid_shape[1])] for row in range(self._grid_shape[0])]\n",
    "        return _grid\n",
    "\n",
    "    def __update_agent_view(self, agent_i):\n",
    "        for row in range(self.agent_prev_pos[agent_i][0],\n",
    "                         self.agent_prev_pos[agent_i][0]):\n",
    "            self._full_obs[row][self.agent_prev_pos[agent_i][1]] = PRE_IDS['empty']\n",
    "\n",
    "        for row in range(self.agent_pos[agent_i][0], self.agent_pos[agent_i][0]):\n",
    "            self._full_obs[row][self.agent_pos[agent_i][1]] = PRE_IDS['agent'] + str(agent_i + 1) \\\n",
    "                                                              + '_' + str(row - self.agent_pos[agent_i][0])\n",
    "\n",
    "#     def __draw_base_img(self):\n",
    "#         self._base_img = draw.draw_grid(self._grid_shape[0], self._grid_shape[1],\n",
    "#                                    cell_size=CELL_SIZE, fill='white', line_color='white')\n",
    "\n",
    "    def __init_full_obs(self):\n",
    "        self._full_obs = self.__create_grid()\n",
    "        for agent_i in range(self.n_agents):\n",
    "            self.__update_agent_view(agent_i)\n",
    "\n",
    "        for agent_i in range(self.n_agents):\n",
    "            self.__update_agent_view(agent_i)\n",
    "\n",
    "#         self.__draw_base_img()\n",
    "\n",
    "    #Countdown timer as 24 second shot clock for each round\n",
    "    #https://www.geeksforgeeks.org/how-to-create-a-countdown-timer-using-python/\n",
    "#     def countdown(self, t=24):     \n",
    "#         while t: \n",
    "#             mins, secs = divmod(t, 60) \n",
    "#             timer = '{:02d}:{:02d}'.format(mins, secs)  \n",
    "#             time.sleep(1) \n",
    "#             t -= 1\n",
    "#             self.t = t\n",
    "    \n",
    "#     def __init_countdown(self, t):\n",
    "#         return self.countdown(t)\n",
    "        \n",
    "\n",
    "    def get_agent_obs(self):\n",
    "        _obs = []\n",
    "\n",
    "        for agent_i in range(self.n_agents):\n",
    "            pos = self.agent_pos[agent_i]\n",
    "            _agent_i_obs_a = pos[0] / self._grid_shape[0]\n",
    "            _agent_i_obs_b = pos[1] / self._grid_shape[1]\n",
    "            \n",
    "            _obs.append(_agent_i_obs_a)\n",
    "            _obs.append(_agent_i_obs_b)\n",
    "\n",
    "        return np.array(_obs)\n",
    "    \n",
    "    def get_state_num(self):\n",
    "        for agent_i in range(self.n_agents):\n",
    "            return self.agent_pos[agent_i][0]*self._grid_shape[0] + self.agent_pos[agent_i][1]\n",
    "\n",
    "    def get_pos_from_state_num(self, state_num):\n",
    "        return (state_num // self._grid_shape[0], state_num % self._grid_shape[0])\n",
    "    \n",
    "##############\n",
    "#Define Reset#   \n",
    "##############\n",
    "\n",
    "    def reset(self):\n",
    "        self._rounds = 0\n",
    "#         self.__init_countdown(24)\n",
    "        \n",
    "        #Set starting positions for agents in Team A\n",
    "        self.agent_pos[0] = [self._grid_shape[0]//2, self._grid_shape[1] - 2]\n",
    "        self.agent_pos[1] = [self._grid_shape[0]//5, self._grid_shape[1] - 2]\n",
    "\n",
    "        \n",
    "        #Set starting positions for agents in Team B\n",
    "        self.agent_pos[2] = [self._grid_shape[0]//2, self._grid_shape[1] - 8]\n",
    "        self.agent_pos[3] = [self._grid_shape[0]//5, self._grid_shape[1] - 8]\n",
    "\n",
    "        \n",
    "        self.agent_prev_pos = {_: self.agent_pos[_] for _ in range(self.n_agents)}\n",
    "        self._agent_dones = False\n",
    "        self.__init_full_obs()\n",
    "        self._step_count = 0\n",
    "        self._total_episode_reward = [0 for _ in range(self.n_teams)]\n",
    "\n",
    "        return self.get_agent_obs()\n",
    "\n",
    "    \n",
    "###############################\n",
    "#Define Properties and Actions#   \n",
    "###############################\n",
    "    \n",
    "            \n",
    "    #This will determine success of an action\n",
    "    def action_success(self, p_1):\n",
    "        return np.random.choice([0, 1], p=[1 - p_1, p_1])\n",
    "\n",
    "    #Determine if a player is close to the goal\n",
    "    def close_range(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if np.sqrt((self.pos[agent_i][0] - GOAL[0])**2 + (self.pos[agent_i][1]-GOAL[1])**2) <= 6:\n",
    "                player._close_range = True\n",
    "                player._midrange = False\n",
    "                player._three_point_range = False\n",
    "\n",
    "    #Determine if a player is mid-range from the goal\n",
    "    def midrange(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if player._close_range == False and player._three_point_range == False:\n",
    "                player._midrange = True\n",
    "                    \n",
    "\n",
    "    #Determine if a player is in three point range\n",
    "    def _three_point_range(self):\n",
    "        for agent_i in range(n_agents):\n",
    "            if self.pos[agent_i][1] <= 19.67 and self.pos[agent_i][0] <= 6.67 or self.pos[agent_i][1] >= 93.33:\n",
    "                player._three_point_range = True\n",
    "            elif self.pos[agent_i][1] > 19.67 and np.sqrt((self.pos[agent_i][0] - GOAL[0])**2 + (self.pos[agent_i][1]-GOAL[1])**2) > 44.3:\n",
    "                player._three_point_range = True\n",
    "                player._midrange = False\n",
    "                player._close_range = False\n",
    "        \n",
    "    def rebound(self):\n",
    "        if self.action_success(0.3):\n",
    "            #UPDATE THE PLAYER_W_BALL:\n",
    "#                 o_rebounder = random.choice([[True, False], [False, True]])\n",
    "#                 self.player_w_ball = o_rebounder\n",
    "#                 self.__init_countdown(14)\n",
    "#                 if o_rebounder == [True, False]:\n",
    "#                     player._has_ball = True\n",
    "#                     player2._has_ball = False\n",
    "#                 else:\n",
    "#                     player._has_ball = False\n",
    "#                     player2._has_ball = True\n",
    "            return 0.2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    #define shot, a made shot will be a reward for the offensive team\n",
    "    def shot(self):\n",
    "\n",
    "        #Can only shoot if the player has the ball -- [1,0]\n",
    "        if self.player_w_ball==[1,0]:\n",
    "\n",
    "            #Close range shot\n",
    "            if player._close_range:\n",
    "                if self.action_success(player.shooting_close):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "            #3 point shot\n",
    "            if player._three_point_range:\n",
    "                if self.action_success(player.shooting3pts):\n",
    "                    return 3\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "            #Midrange shot\n",
    "            else:\n",
    "                if self.action_success(player.shooting_midrange):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "        #Can only shoot if the player has the ball -- [0,1]\n",
    "        if self.player_w_ball==[0,1]:\n",
    "\n",
    "            #Close range shot\n",
    "            if player2._close_range:\n",
    "                if self.action_success(player2.shooting_close):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "            #3 point shot\n",
    "            if player2._three_point_range:\n",
    "                if self.action_success(player2.shooting3pts):\n",
    "                    return 3\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "\n",
    "            #Midrange shot\n",
    "            else:\n",
    "                if self.action_success(player2.shooting_midrange):\n",
    "                    return 2\n",
    "                else:\n",
    "                    return self.rebound()\n",
    "                        \n",
    "    def ball_pass(self):\n",
    "        if self.player_w_ball == [1,0]:\n",
    "            player._has_ball = False\n",
    "            player2._has_ball = True\n",
    "            self.player_w_ball = [0,1]\n",
    "\n",
    "        if self.player_w_ball == [0,1]:\n",
    "            player._has_ball = True\n",
    "            player2._has_ball = False\n",
    "            self.player_w_ball = [1,0]\n",
    "                \n",
    "            \n",
    "\n",
    "    def defended(self):\n",
    "        for agent_j in [2,3]:\n",
    "            if np.sqrt(self.pos[0][0]-self.pos[agent_j][0]**2 + self.pos[0][1]-self.pos[agent_j][1]**2) < 5:\n",
    "                player._is_defended=True\n",
    "            if np.sqrt(self.pos[1][0]-self.pos[agent_j][0]**2 + self.pos[1][1]-self.pos[agent_j][1]**2) < 5:\n",
    "                player2._is_defended=True\n",
    "            else:\n",
    "                player._is_defended=False\n",
    "                player2._is_defended=False\n",
    "    \n",
    "    def steal(self):\n",
    "        if player._has_ball and player._is_defended:\n",
    "            return action_success(0.02)\n",
    "        if player2._has_ball and player2._is_defended:\n",
    "            return action_success(0.02)\n",
    "        \n",
    "    \n",
    "    def block(self):\n",
    "        if player._has_ball and player._is_defended and player._close_range:\n",
    "            return action_success(0.04)\n",
    "        if player._has_ball and player._is_defended and player._midrange:\n",
    "            return action_success(0.03)\n",
    "        if player._has_ball and player._is_defended and player._three_point_range:\n",
    "            return action_success(0.02)\n",
    "        if player2._has_ball and player2._is_defended and player2._close_range:\n",
    "            return action_success(0.04)\n",
    "        if player2._has_ball and player2._is_defended and player2._midrange:\n",
    "            return action_success(0.03)\n",
    "        if player2._has_ball and player2._is_defended and player2._three_point_range:\n",
    "            return action_success(0.02)\n",
    "                \n",
    "    def out_of_bounds(self):\n",
    "        for agent_x in range(self.n_agents):\n",
    "            if self.agent_pos[agent_x][0] > 0 and self.agent_pos[agent_x][0] < self._grid_shape[0] and self.agent_pos[agent_x][1] > 0 and self.agent_pos[agent_x][1] < self._grid_shape[1]:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "    def is_valid(self, pos):\n",
    "        return (0 <= pos[0] < self._grid_shape[0]) and (0 <= pos[1] < self._grid_shape[1])\n",
    "\n",
    "    def _is_cell_vacant(self, pos):\n",
    "        return self.is_valid(pos) and (self._full_obs[pos[0]][pos[1]] == PRE_IDS['empty'])\n",
    "\n",
    "    \n",
    "    \n",
    "###############\n",
    "#Define Render#   \n",
    "###############\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        img = copy.copy(self._base_img)\n",
    "        for agent_i in range(self.n_agents):\n",
    "            for row in self.agent_pos[agent_i][0]:\n",
    "                fill_cell(img, (row, self.agent_pos[agent_i][1]), cell_size=CELL_SIZE, fill=AGENT_COLORS[agent_i])\n",
    "\n",
    "        img = draw_border(img, border_width=2, fill='gray')\n",
    "\n",
    "        img = np.asarray(img)\n",
    "        if mode == 'rgb_array':\n",
    "            return img\n",
    "        elif mode == 'human':\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "            return self.viewer.isopen\n",
    "\n",
    "    def __update_agent_pos(self, agent_i, move):\n",
    "\n",
    "        curr_pos = copy.copy(self.agent_pos[agent_i])\n",
    "        for agent_i in range(self.n_agents):\n",
    "\n",
    "            if move == 0:  # noop\n",
    "                next_pos = None\n",
    "            elif move == 1:  # up\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1]]\n",
    "            elif move == 2:  # upright\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1] + 1]\n",
    "            elif move == 3:  # right\n",
    "                next_pos = [curr_pos[0], curr_pos[1] + 1]\n",
    "            elif move == 4:  # downright\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1] + 1]\n",
    "            elif move == 5:  # down\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1]]\n",
    "            elif move == 6:  # downleft\n",
    "                next_pos = [curr_pos[0] + 1, curr_pos[1] - 1]\n",
    "            elif move == 7:  # left\n",
    "                next_pos = [curr_pos[0], curr_pos[1] - 1]\n",
    "            elif move == 8:  # upleft\n",
    "                next_pos = [curr_pos[0] - 1, curr_pos[1] - 1]\n",
    "#                 else:\n",
    "#                     raise Exception('Action Not found!')\n",
    "\n",
    "\n",
    "            if move in range(1,9):\n",
    "                self.agent_prev_pos[agent_i] = self.agent_pos[agent_i]\n",
    "                self.agent_pos[agent_i] = next_pos\n",
    "                self.__update_agent_view(agent_i)\n",
    "            \n",
    "\n",
    "#############\n",
    "#Define Seed#   \n",
    "#############\n",
    "\n",
    "    def seed(self, n=None):\n",
    "        self.np_random, seed = seeding.np_random(n)\n",
    "        return [seed]\n",
    "\n",
    "#############\n",
    "#Define Step#   \n",
    "#############\n",
    "    \n",
    "    def step(self, action_n=[0,0,0,0]):\n",
    "        assert len(action_n) == self.n_agents\n",
    "        self._step_count += 1\n",
    "        rewards = [self._step_cost for _ in range(self.n_teams)]\n",
    "        \n",
    "        for agent, action in enumerate(action_n):\n",
    "            \n",
    "            if action == \"UP\" and self.agent_pos[agent][1] > 0:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "            elif action == \"UPLEFT\" and self.agent_pos[agent][1] > 0 and self.agent_pos[agent][0] > 0:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "            elif action == \"LEFT\" and self.agent_pos[agent][0] > 0:\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "            elif action == \"DOWNLEFT\" and self.agent_pos[agent][0] > 0 and self.agent_pos[agent][1] < self._grid_shape[1]-1:\n",
    "                self.agent_pos[agent][0] -= 1\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"DOWN\" and self.agent_pos[agent][1] < self._grid_shape[1]-1:\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"DOWNRIGHT\" and self.agent_pos[agent][1] < self._grid_shape[1]-1  and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][1] += 1\n",
    "            elif action == \"RIGHT\" and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][0] += 1\n",
    "            elif action == \"UPRIGHT\" and self.agent_pos[agent][1] > 0 and self.agent_pos[agent][0] < self._grid_shape[0]-1:\n",
    "                self.agent_pos[agent][1] -= 1\n",
    "                self.agent_pos[agent][0] += 1\n",
    "                \n",
    "            if agent == 0 or agent == 1:\n",
    "                if action_n == 'SHOOT':\n",
    "                    self.shot()\n",
    "                    # if shot made, new round\n",
    "                    if fga == 2:\n",
    "                        rewards = [2, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 3:\n",
    "                        rewards = [3, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 1:\n",
    "                        rewards = [0, 1]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                    elif fga == 0.2:\n",
    "                        rewards = [0.2, 0]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                elif action_n == 'BALL_PASS':\n",
    "                    self.ball_pass()\n",
    "            if agent == 2 or agent == 3:\n",
    "                if action_n == 'BALL_PASS':\n",
    "                    st = self.steal()\n",
    "                    # if steal made, new round\n",
    "                    if st == 1:\n",
    "                        rewards = [0, 2]\n",
    "                        self._rounds += 1\n",
    "\n",
    "                elif action_n == 'SHOOT':\n",
    "                    bl = self.block()\n",
    "                    # if block made, new round\n",
    "                    if bl == 1:\n",
    "                        rewards = [0, 2]\n",
    "                        self._rounds += 1\n",
    "            \n",
    "        # if Offense fails to get off a shot within time limit, new round\n",
    "#         if self.t < 1:\n",
    "#             rewards = [0, 2]\n",
    "#             self._agent_dones = True\n",
    "#             self._rounds += 1\n",
    "            \n",
    "        if self.out_of_bounds():\n",
    "            rewards = [-10, -10]\n",
    "            self._rounds +=1\n",
    "            \n",
    "        if self.rebound() == 0.2:\n",
    "            rewards = [0.2, 0]\n",
    "            self._rounds +=1\n",
    "            \n",
    "        if self.rebound() == 1:\n",
    "            rewards = [0, 1]\n",
    "            self._rounds += 1\n",
    "                        \n",
    "        if self._rounds == self._max_rounds:\n",
    "            self._agent_dones = True\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            for agent_i in range(self.n_agents_team_A):\n",
    "                self.__update_agent_pos(agent_i, action_n[agent_i])\n",
    "            for agent_j in range(self.n_agents_team_B):\n",
    "                self.__update_agent_pos(agent_j, action_n[agent_j])\n",
    "                \n",
    "        for i in range(self.n_teams):\n",
    "            self._total_episode_reward[i] += rewards[i]\n",
    "\n",
    "        return self.get_agent_obs(), rewards[0]-rewards[1], self._agent_dones, {'rounds': self._rounds}\n",
    "    \n",
    "    def close(self):\n",
    "        if self.viewer is not None:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "# Define constants for clearer code\n",
    "\n",
    "CELL_SIZE = 5\n",
    "\n",
    "#Goal Location\n",
    "GOAL = [50, 10.5]\n",
    "\n",
    "ACTION_MEANING = {\n",
    "    0 : 'NOOP',\n",
    "    1 : 'UP',\n",
    "    2 : 'UPRIGHT',\n",
    "    3 : 'RIGHT',\n",
    "    4 : 'DOWNRIGHT',\n",
    "    5 : 'DOWN',\n",
    "    6 : 'DOWNLEFT',\n",
    "    7 : 'LEFT',\n",
    "    8 : 'UPLEFT',\n",
    "    9 : 'BALL_PASS',\n",
    "    10 : 'SHOOT',\n",
    "}\n",
    "\n",
    "AGENT_TEAMS = {\n",
    "    0: 'A',\n",
    "    1: 'A',\n",
    "    2: 'B',\n",
    "    3: 'B',\n",
    "}\n",
    "\n",
    "AGENT_COLORS = {\n",
    "    0: 'red',\n",
    "    1: 'red',\n",
    "    2: 'blue',\n",
    "    3: 'blue',\n",
    "}\n",
    "\n",
    "WALL_COLOR = 'black'\n",
    "\n",
    "# each pre-id should be unique and single char\n",
    "PRE_IDS = {\n",
    "    'agent': 'A',\n",
    "    'goal' : 'G',\n",
    "    'empty': 'O'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agent Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgentA:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0\n",
    "        player = Player('Luka Doncic', _has_ball=True)\n",
    "        player2 = Player('Kristaps Porzingis', _has_ball=False)\n",
    "        player3 = Player('RJ Barrett', _has_ball=False)\n",
    "        player4 = Player('Julius Randle', _has_ball=False)\n",
    "\n",
    "    def step(self, env):\n",
    "        # current_obs = env.get_observation()\n",
    "        actions = ACTION_MEANING\n",
    "        action = [random.choice(actions), random.choice(actions), random.choice(actions), random.choice(actions)]\n",
    "        reward = env.step(action)\n",
    "        print(f\"Took action {action} and got reward {self.total_reward}\")\n",
    "        self.total_reward += reward[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RandomAgentA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BasketballEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took action ['DOWNLEFT', 'DOWNRIGHT', 'UPRIGHT', 'DOWNLEFT'] and got reward -2.6\n",
      "Total reward: -3.6\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "count = 0\n",
    "while not env.is_done():\n",
    "    agent.step(env)\n",
    "    count+=1\n",
    "print(f\"Total reward: {agent.total_reward}\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "The reward function for the random agent loop isn't clear so I will step through random actions in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.48      , 0.9893617 , 0.19      , 0.9787234 , 0.51      ,\n",
       "        0.90425532, 0.2       , 0.92553191]),\n",
       " -1,\n",
       " False,\n",
       " {'rounds': 3})"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([random.choice(ACTION_MEANING),random.choice(ACTION_MEANING),random.choice(ACTION_MEANING),random.choice(ACTION_MEANING)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "The environment is working. The agents are not in their initial positions and the reward was given to the defense for a defensive rebound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount for future rewards\n",
    "gamma = 0.9\n",
    "\n",
    "# the learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "# exploration-exploitation tradeoff: proportion of time to take a random action\n",
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player = Player('RJ Barrett', _has_ball=True)\n",
    "player2 = Player('Julius Randle', _has_ball=False)\n",
    "env = BasketballEnv()\n",
    "env.reset()\n",
    "episodes = 100000\n",
    "\n",
    "# Q(s,a): \"quality\" of taking action a in state s\n",
    "num_states = env._grid_shape[0]*env._grid_shape[1]\n",
    "num_actions = len(ACTION_MEANING)\n",
    "q_table = np.zeros([num_states, num_actions])\n",
    "\n",
    "for _ in range(0,episodes):\n",
    "    player = Player('Luka Doncic', _has_ball=True)\n",
    "    player2 = Player('Kristaps Porzingis', _has_ball=False)\n",
    "\n",
    "    env.reset()\n",
    "    state = env.get_state_num()\n",
    "\n",
    "    while not env.is_done():\n",
    "        # epsilon-greedy policy\n",
    "        actions = ACTION_MEANING\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = [random.choice(actions), random.choice(actions), random.choice(actions), random.choice(actions)]\n",
    "        else:\n",
    "            action_index = np.random.choice(np.flatnonzero(q_table[state] == q_table[state].max()))\n",
    "            action = [actions[action_index], actions[action_index], actions[action_index], actions[action_index]]\n",
    "\n",
    "        reward = env.step(action)[1]\n",
    "        state2 = env.get_state_num()\n",
    "\n",
    "        # Q-update\n",
    "        old_q = q_table[state,action_index]\n",
    "        max_q2 = np.max(q_table[state2])\n",
    "        q_table[state,action_index] = old_q + alpha*(reward + gamma*max_q2 - old_q)\n",
    "\n",
    "        #print(f\"s={state}, a={action}, s'={state2}, r={reward}, old_q={old_q}, new_q={q_table[state,action_index]}\")\n",
    "\n",
    "        state = state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if there are non-zero values in the q-table that aren't being seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(q_table).value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,12))\n",
    "sns.heatmap(q_table[4600:5400], vmin=0, vmax=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_per_grid = 5\n",
    "im = Image.open('../images/Basketball_court-Model.jpg')\n",
    "draw = ImageDraw.Draw(im)\n",
    "# im = im.rotate(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 600)"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent_i in [0,1]:\n",
    "    drawCirc(draw, env.agent_pos[agent_i][0]*5, env.agent_pos[agent_i][1]*5, 'blue')\n",
    "for agent_i in [2,3]:\n",
    "    drawRect(draw, env.agent_pos[agent_i][0]*5, env.agent_pos[agent_i][1]*5, 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env._grid_shape[1]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.new(\"RGB\", (500, 470), 'white')\n",
    "drawText = ImageDraw.Draw(image)\n",
    "fnt = ImageFont.truetype(\"C:/Windows/Fonts/arial.ttf \", 36)\n",
    "def drawText(img, txt, x, y, color):\n",
    "    img.text([x*image.size[0], y*image.size[1]], txt, fnt=fnt, fill=color)\n",
    "\n",
    "if q_table is not None:\n",
    "        arrows = ['N/A', '^','^>','>','v>','v','<v','<','^<', 'O', 'P']\n",
    "        num_states = env._grid_shape[0] * env._grid_shape[1]\n",
    "        for s in range(num_states):\n",
    "            (x,y) = env.get_pos_from_state_num(s)\n",
    "            action_index = np.argmax(q_table[s])\n",
    "            arrow = arrows[action_index]\n",
    "            drawText(draw, arrow, x, y, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization parameters\n",
    "gridsize = 5    # pixels per grid square\n",
    "border = 1         # in pixels\n",
    "\n",
    "def drawRect(img, x, y, color):\n",
    "    img.rectangle([x*gridsize+4*border, y*gridsize+4*border, (x+1)*gridsize-2*border, (y+1)*gridsize-2*border], fill=color)\n",
    "\n",
    "def drawCirc(img, x, y, color):\n",
    "    img.rectangle([x*gridsize+4*border, y*gridsize+4*border, (x+1)*gridsize-2*border, (y+1)*gridsize-2*border], fill=color)    \n",
    "    \n",
    "def drawText(img, txt, x, y, color):\n",
    "    img.text([x*gridsize+4*border, y*gridsize+4*border], txt, fnt=fnt, fill=color)\n",
    "\n",
    "def drawEnvironment(env, q_table=None):\n",
    "    imageSize = env._grid_shape[0]*env._grid_shape[1]*gridsize + border*2\n",
    "    image = Image.new(\"RGB\", (imageSize, imageSize), 'white')\n",
    "    imageDraw = ImageDraw.Draw(image)\n",
    "    # draw the grid\n",
    "    for row in range(env._grid_shape[0]+1):\n",
    "        imageDraw.line([border, row*gridsize+border, imageSize-border, row*gridsize+border], 'black', border)\n",
    "    for col in range(env._grid_shape[1]+1):\n",
    "        imageDraw.line([col*gridsize+border, border, col*gridsize+border, imageSize-border], 'black', border)\n",
    "\n",
    "    # agent is blue, goal is red, and walls are black\n",
    "    for agent_i in [0,1]:\n",
    "        drawCirc(imageDraw, env.agent_pos[agent_i][0], env.agent_pos[agent_i][1], 'blue')\n",
    "    for agent_i in [2,3]:\n",
    "        drawRect(imageDraw, env.agent_pos[agent_i][0], env.agent_pos[agent_i][1], 'blue')\n",
    "\n",
    "    drawItem(imageDraw, env.GOAL[0], env.GOAL[1], 'orange')\n",
    "\n",
    "    if q_table is not None:\n",
    "        arrows = ['^','^>','>','v>','v','<v','<','^<', 'O', 'P']\n",
    "        num_states = env.num_states()\n",
    "        for s in range(num_states):\n",
    "            (x,y) = env.get_pos_from_state_num(s)\n",
    "            action_index = np.argmax(q_table[s])\n",
    "            arrow = arrows[action_index]\n",
    "            drawText(imageDraw, arrow, x, y, 'green')\n",
    "\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a44bd6e9d0bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdrawEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBasketballEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-15ee1edc2b72>\u001b[0m in \u001b[0;36mdrawEnvironment\u001b[1;34m(env, q_table)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# agent is blue, goal is red, and walls are black\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0magent_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdrawItem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageDraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0magent_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdrawItem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageDraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0magent_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "drawEnvironment(BasketballEnv(), q_table=q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO - Promixal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BasketballEnv')\n",
    "\n",
    "model = PPO1(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo1_Basketball\")\n",
    "\n",
    "# model = PPO1.load(\"ppo1_cartpole\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_baselines.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "Analysis of the PPO Model results go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO2 - Promixal Policy Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess environment\n",
    "env = make_vec_env('BasketballEnv', n_envs=4)\n",
    "\n",
    "model = PPO2(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo2_basketball\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO2.load(\"ppo2_basketball\")\n",
    "\n",
    "# Enjoy trained agent\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_baselines.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "Analysis of the PPO2 Model results go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C - Advantage Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines.readthedocs.io/en/master/modules/a2c.html\n",
    "# Parallel environments\n",
    "env = make_vec_env('BasketballEnv', n_envs=4)\n",
    "\n",
    "model = A2C(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"a2c_basketball\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = A2C.load(\"a2c_cartpole\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_baselines.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis:\n",
    "Analysis of the A2C Model results go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
